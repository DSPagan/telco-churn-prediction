{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cc29e7",
   "metadata": {},
   "source": [
    "\n",
    "# Customer Churn Prediction â€” Modeling, Selection & Explainability\n",
    "\n",
    "**Objective:** Build, select, and explain a predictive model for customer churn using preprocessed datasets.  \n",
    "**Deliverables:** Model selection table, final test metrics, ROC/PR curves, SHAP explainability, and a persisted final model.\n",
    "\n",
    "**Setup:**  \n",
    "- **Inputs** (already preprocessed): `data/processed/X_train.parquet`, `y_train.parquet`, `X_eval.parquet`, `y_eval.parquet`, `X_test.parquet`, `y_test.parquet`  \n",
    "- **Outputs:**  \n",
    "  - `reports/model_selection_results.csv`, `reports/test_metrics.json`  \n",
    "  - `reports/figures/` (ROC, PR, confusion matrix, SHAP)  \n",
    "  - `models/final_<model>.joblib`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2827a",
   "metadata": {},
   "source": [
    "## Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb009e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# I/O\n",
    "DATA_DIR = Path(\"data/processed\")\n",
    "REPORTS_DIR = Path(\"reports\")\n",
    "FIG_DIR = REPORTS_DIR / \"figures\"\n",
    "MODELS_DIR = Path(\"models\")\n",
    "for d in [REPORTS_DIR, FIG_DIR, MODELS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb8d8e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94968c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = pd.read_parquet(DATA_DIR / \"X_train.parquet\")\n",
    "y_train = pd.read_parquet(DATA_DIR / \"y_train.parquet\").squeeze()\n",
    "\n",
    "X_eval  = pd.read_parquet(DATA_DIR / \"X_eval.parquet\")\n",
    "y_eval  = pd.read_parquet(DATA_DIR / \"y_eval.parquet\").squeeze()\n",
    "\n",
    "X_test  = pd.read_parquet(DATA_DIR / \"X_test.parquet\")\n",
    "y_test  = pd.read_parquet(DATA_DIR / \"y_test.parquet\").squeeze()\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \" X_eval:\", X_eval.shape, \" X_test:\", X_test.shape)\n",
    "print(\"Positive rate (train/eval/test):\",\n",
    "      y_train.mean().round(3), y_eval.mean().round(3), y_test.mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0ad33",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic feature sanity\n",
    "assert set(X_train.columns) == set(X_eval.columns) == set(X_test.columns), \"Column mismatch across splits\"\n",
    "assert len(X_train) == len(y_train) and len(X_eval) == len(y_eval) and len(X_test) == len(y_test), \"Length mismatch\"\n",
    "\n",
    "# Class imbalance overview\n",
    "class_imbalance = pd.DataFrame({\n",
    "    \"split\": [\"train\", \"eval\", \"test\"],\n",
    "    \"positive_rate\": [y_train.mean(), y_eval.mean(), y_test.mean()]\n",
    "})\n",
    "class_imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1adc870",
   "metadata": {},
   "source": [
    "## Cross-Validation Strategy & Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "SCORING = \"f1\"\n",
    "N_JOBS  = -1\n",
    "N_ITER  = 30   # runtime-controlled exploration\n",
    "VERBOSE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ac555",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44651ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression (preprocessed data, no pipeline needed here)\n",
    "param_dist_lr = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "param_dist_rf = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "param_dist_xgb = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 6, 9],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"min_child_weight\": [1, 5],\n",
    "    \"reg_alpha\": [0, 0.1],\n",
    "    \"reg_lambda\": [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc69a41",
   "metadata": {},
   "source": [
    "## Model Training (RandomizedSearchCV on Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "searches = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500, random_state=SEED)\n",
    "search_lr = RandomizedSearchCV(\n",
    "    lr, param_distributions=param_dist_lr, n_iter=N_ITER,\n",
    "    scoring=SCORING, cv=cv, n_jobs=N_JOBS, verbose=VERBOSE, random_state=SEED\n",
    ")\n",
    "search_lr.fit(X_train, y_train)\n",
    "searches[\"LogisticRegression\"] = search_lr\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "search_rf = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist_rf, n_iter=N_ITER,\n",
    "    scoring=SCORING, cv=cv, n_jobs=N_JOBS, verbose=VERBOSE, random_state=SEED\n",
    ")\n",
    "search_rf.fit(X_train, y_train)\n",
    "searches[\"RandomForest\"] = search_rf\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = xgb.XGBClassifier(random_state=SEED, eval_metric=\"logloss\", verbosity=1)\n",
    "search_xgb = RandomizedSearchCV(\n",
    "    xgb_clf, param_distributions=param_dist_xgb, n_iter=N_ITER,\n",
    "    scoring=SCORING, cv=cv, n_jobs=N_JOBS, verbose=VERBOSE, random_state=SEED\n",
    ")\n",
    "search_xgb.fit(X_train, y_train)\n",
    "searches[\"XGBoost\"] = search_xgb\n",
    "\n",
    "print(\"Searches completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96ab7d",
   "metadata": {},
   "source": [
    "## Model Comparison on Eval Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_on_eval(name, search, X_eval, y_eval):\n",
    "    best_est = search.best_estimator_\n",
    "    y_pred = best_est.predict(X_eval)\n",
    "    if hasattr(best_est, \"predict_proba\"):\n",
    "        y_proba = best_est.predict_proba(X_eval)[:, 1]\n",
    "    else:\n",
    "        # fallback: probability-free models\n",
    "        y_proba = None\n",
    "\n",
    "    out = {\n",
    "        \"model\": name,\n",
    "        \"cv_f1\": round(search.best_score_, 4),\n",
    "        \"eval_f1\": round(f1_score(y_eval, y_pred), 4),\n",
    "        \"eval_precision\": round(precision_score(y_eval, y_pred), 4),\n",
    "        \"eval_recall\": round(recall_score(y_eval, y_pred), 4),\n",
    "        \"eval_accuracy\": round(accuracy_score(y_eval, y_pred), 4),\n",
    "        \"best_params\": search.best_params_\n",
    "    }\n",
    "    if y_proba is not None:\n",
    "        out[\"eval_roc_auc\"] = round(roc_auc_score(y_eval, y_proba), 4)\n",
    "    return out\n",
    "\n",
    "results = [evaluate_on_eval(n, s, X_eval, y_eval) for n, s in searches.items()]\n",
    "results_df = pd.DataFrame(results).sort_values(\"eval_f1\", ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f16ab",
   "metadata": {},
   "source": [
    "## Retrain Best Model on Train+Eval and Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Winner by eval_f1\n",
    "winner_name = results_df.iloc[0][\"model\"]\n",
    "winner_params = searches[winner_name].best_params_\n",
    "print(f\"Winner: {winner_name}\\nParams: {winner_params}\")\n",
    "\n",
    "# Merge train + eval for final training\n",
    "X_full = pd.concat([X_train, X_eval], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_eval], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Instantiate final model\n",
    "if winner_name == \"LogisticRegression\":\n",
    "    final_model = LogisticRegression(max_iter=500, random_state=SEED, **winner_params)\n",
    "elif winner_name == \"RandomForest\":\n",
    "    final_model = RandomForestClassifier(random_state=SEED, **winner_params)\n",
    "else:\n",
    "    final_model = xgb.XGBClassifier(random_state=SEED, eval_metric=\"logloss\", **winner_params)\n",
    "\n",
    "# Fit & predict\n",
    "final_model.fit(X_full, y_full)\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "y_proba_test = final_model.predict_proba(X_test)[:, 1] if hasattr(final_model, \"predict_proba\") else None\n",
    "\n",
    "# Metrics\n",
    "test_metrics = {\n",
    "    \"test_f1\": f1_score(y_test, y_pred_test),\n",
    "    \"test_precision\": precision_score(y_test, y_pred_test),\n",
    "    \"test_recall\": recall_score(y_test, y_pred_test),\n",
    "    \"test_accuracy\": accuracy_score(y_test, y_pred_test)\n",
    "}\n",
    "if y_proba_test is not None:\n",
    "    test_metrics[\"test_roc_auc\"] = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "print(pd.Series(test_metrics).round(4))\n",
    "\n",
    "# Confusion Matrix (print + plot)\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760ab3f",
   "metadata": {},
   "source": [
    "## Plots â€” ROC, Precision-Recall, and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROC Curve\n",
    "if y_proba_test is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba_test)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (Test)\")\n",
    "    plt.legend()\n",
    "    roc_path = FIG_DIR / \"roc_curve_test.png\"\n",
    "    plt.tight_layout(); plt.savefig(roc_path, dpi=150); plt.close()\n",
    "    print(\"Saved:\", roc_path)\n",
    "\n",
    "# PR Curve\n",
    "if y_proba_test is not None:\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(recall, precision, label=\"PR\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve (Test)\")\n",
    "    plt.legend()\n",
    "    pr_path = FIG_DIR / \"pr_curve_test.png\"\n",
    "    plt.tight_layout(); plt.savefig(pr_path, dpi=150); plt.close()\n",
    "    print(\"Saved:\", pr_path)\n",
    "\n",
    "# Confusion Matrix Heatmap (simple)\n",
    "plt.figure(figsize=(4,4))\n",
    "# No custom colors per your plotting constraints\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix (Test)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [\"No\", \"Yes\"], rotation=45)\n",
    "plt.yticks(tick_marks, [\"No\", \"Yes\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "cm_path = FIG_DIR / \"confusion_matrix_test.png\"\n",
    "plt.tight_layout(); plt.savefig(cm_path, dpi=150); plt.close()\n",
    "print(\"Saved:\", cm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203331a3",
   "metadata": {},
   "source": [
    "## Persist Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model selection table & test metrics\n",
    "results_df.to_csv(REPORTS_DIR / \"model_selection_results.csv\", index=False)\n",
    "with open(REPORTS_DIR / \"test_metrics.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k, v in test_metrics.items()}, f, indent=2)\n",
    "print(\"Saved model selection and test metrics.\")\n",
    "\n",
    "# Final model\n",
    "model_path = MODELS_DIR / f'final_{winner_name.lower().replace(\" \", \"_\")}.joblib'\n",
    "joblib.dump(final_model, model_path)\n",
    "print(\"Saved model to:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcfd1b9",
   "metadata": {},
   "source": [
    "## Explainability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tree-based -> TreeExplainer; otherwise KernelExplainer (slower)\n",
    "is_tree = isinstance(final_model, (RandomForestClassifier, xgb.XGBClassifier))\n",
    "\n",
    "if is_tree:\n",
    "    explainer = shap.TreeExplainer(final_model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Summary (positive class for binary)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "        shap.summary_plot(shap_values[1], X_test, show=False)\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, X_test, show=False)\n",
    "    shap_sum_path = FIG_DIR / \"shap_summary.png\"\n",
    "    plt.tight_layout(); plt.savefig(shap_sum_path, dpi=150); plt.close()\n",
    "    print(\"Saved:\", shap_sum_path)\n",
    "\n",
    "    # Importance bar (mean |SHAP|)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "        shap.summary_plot(shap_values[1], X_test, plot_type=\"bar\", show=False)\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "    shap_bar_path = FIG_DIR / \"shap_importance_bar.png\"\n",
    "    plt.tight_layout(); plt.savefig(shap_bar_path, dpi=150); plt.close()\n",
    "    print(\"Saved:\", shap_bar_path)\n",
    "\n",
    "else:\n",
    "    # KernelExplainer with small background for speed\n",
    "    background = X_train.sample(min(500, len(X_train)), random_state=SEED)\n",
    "    explainer = shap.KernelExplainer(final_model.predict_proba, background)\n",
    "    sample_X = X_test.sample(min(1000, len(X_test)), random_state=SEED)\n",
    "    shap_values = explainer.shap_values(sample_X)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    shap.summary_plot(shap_values[1], sample_X, show=False)\n",
    "    shap_sum_path = FIG_DIR / \"shap_summary.png\"\n",
    "    plt.tight_layout(); plt.savefig(shap_sum_path, dpi=150); plt.close()\n",
    "    print(\"Saved:\", shap_sum_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc236836",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "- Threshold tuning to hit business targets (e.g., maximize recall at fixed precision).\n",
    "- Segment-level error analysis (e.g., by Contract, Tenure).\n",
    "- Calibrated probabilities (`CalibratedClassifierCV`) if required by downstream systems.\n",
    "- Packaging for deployment (batch/API) and monitoring (data drift, performance drift).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}